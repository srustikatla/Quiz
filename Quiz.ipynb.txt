{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdQCMYsJpdmC",
        "outputId": "0bb1ed42-68e2-41a9-9aff-eaa6ba1a7171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Shapes of datasets:\n",
            "x_train: (60000, 28, 28)\n",
            "x_test: (10000, 28, 28)\n",
            "x_train_noisy: (60000, 28, 28)\n",
            "x_test_noisy: (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    (x_train, _), (x_test, _) = mnist.load_data()\n",
        "except Exception as e:\n",
        "    print(\"Error loading MNIST dataset:\", e)\n",
        "    exit()\n",
        "\n",
        "# Normalize the images\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Function to add random noise to images\n",
        "def add_noise(images, noise_factor=0.5):\n",
        "    noisy_images = images + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=images.shape)\n",
        "    return np.clip(noisy_images, 0.0, 1.0)\n",
        "\n",
        "# Introduce noise to training and testing images\n",
        "noise_factor = 0.2\n",
        "x_train_noisy = add_noise(x_train, noise_factor)\n",
        "x_test_noisy = add_noise(x_test, noise_factor)\n",
        "\n",
        "# Verify the shapes of the datasets\n",
        "print(\"Shapes of datasets:\")\n",
        "print(\"x_train:\", x_train.shape)\n",
        "print(\"x_test:\", x_test.shape)\n",
        "print(\"x_train_noisy:\", x_train_noisy.shape)\n",
        "print(\"x_test_noisy:\", x_test_noisy.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Encoder\n",
        "input_img = Input(shape=input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Summary of the autoencoder architecture\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dORd6CwVpqxh",
        "outputId": "12e25f19-af41-4b4c-a192-dba8bdfcfa30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 14, 14, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 32)        18464     \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 28, 28, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74497 (291.00 KB)\n",
            "Trainable params: 74497 (291.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.losses import MeanSquaredError\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compile the autoencoder with MSE loss and Adam optimizer\n",
        "autoencoder.compile(optimizer=Adam(), loss=MeanSquaredError())\n",
        "\n",
        "# Train the autoencoder\n",
        "history = autoencoder.fit(x_train_noisy, x_train,\n",
        "                          epochs=10,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(x_test_noisy, x_test))\n",
        "\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z38zsqHpwY6",
        "outputId": "8aa6c6ff-bcdc-4203-9643-732959038d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 204s 431ms/step - loss: 0.1133 - val_loss: 0.1140\n",
            "Epoch 2/10\n",
            "140/469 [=======>......................] - ETA: 2:16 - loss: 0.1118"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import mean_squared_error as mse\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Evaluate the model on test set\n",
        "reconstructed_images = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "# Calculate MSE for evaluation\n",
        "mse_scores = []\n",
        "ssim_scores = []\n",
        "for i in range(len(x_test)):\n",
        "    mse_score = mse(x_test[i], reconstructed_images[i])\n",
        "    mse_scores.append(mse_score)\n",
        "    ssim_score = ssim(x_test[i], reconstructed_images[i], data_range=reconstructed_images[i].max() - reconstructed_images[i].min())\n",
        "    ssim_scores.append(ssim_score)\n",
        "\n",
        "# Calculate average MSE and SSIM scores\n",
        "average_mse = np.mean(mse_scores)\n",
        "average_ssim = np.mean(ssim_scores)\n",
        "print(\"Average MSE:\", average_mse)\n",
        "print(\"Average SSIM:\", average_ssim)\n",
        "\n",
        "# Visualize reconstructed images and compare with ground truth\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # number of images to display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original images\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title('Noisy')\n",
        "\n",
        "    # Display reconstructed images\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(reconstructed_images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.set_title('Reconstructed')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IrSeTj4cqHlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l1\n",
        "\n",
        "# Define a function to create the autoencoder model\n",
        "def create_autoencoder(learning_rate=0.001, batch_size=128, sparsity_regularization=0.01):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    encoded = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(encoded)\n",
        "    decoded = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    decoded = UpSampling2D((2, 2))(decoded)\n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(decoded)\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return autoencoder\n",
        "\n",
        "# Create KerasRegressor based on the defined autoencoder model\n",
        "autoencoder_model = KerasRegressor(build_fn=create_autoencoder, epochs=10, verbose=0)\n",
        "\n",
        "# Define hyperparameter space\n",
        "param_grid = {\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'batch_size': [64, 128, 256],\n",
        "    'sparsity_regularization': [0.001, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(estimator=autoencoder_model, param_distributions=param_grid, n_iter=5, cv=3, verbose=2)\n",
        "random_search_result = random_search.fit(x_train_noisy, x_train)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best parameters found: \", random_search_result.best_params_)\n"
      ],
      "metadata": {
        "id": "pCi7stV7qNyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Define the encoder\n",
        "input_img = Input(shape=input_shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Define the decoder\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "\n",
        "# Compile the autoencoder model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Print model summary\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "id": "eJzZ2gYdqZVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}